[[Markov Decision Processes]] or MDP are not about receiving immediate rewards, but to receive delayed rewards.

These are rewards that you will gain later in a sequence of moves.
